{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec45c29",
   "metadata": {},
   "source": [
    "# This is the simpliest pipeline of Fian.\n",
    "\n",
    "## There are 3 phases\n",
    "\n",
    "- Intent Detection a.k.a NLP layers\n",
    "\n",
    "- Feature Selection\n",
    "\n",
    "- Respond"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f4f18",
   "metadata": {},
   "source": [
    "# Phase 1 - Intent Detection\n",
    "\n",
    "1. Input Preprocessing\n",
    "\n",
    "1. Extract user's intent (using TF-IDF + Logistic Regression)\n",
    "\n",
    "First, for good measure, I will train the model first (train it once and give out a joblib file, but they are here for visualizations)\n",
    "\n",
    "P.S: If you are seeing model and such, means that the part is under developement\n",
    "\n",
    "Second, I will use the model to predict what's the user's intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5308f074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy loaded.\n",
      "Transformers module: <module 'spacy_transformers' from 'c:\\\\Users\\\\lugia\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\spacy_transformers\\\\__init__.py'>\n",
      "Transformer model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import spacy_transformers\n",
    "\n",
    "print(\"spaCy loaded.\")\n",
    "print(\"Transformers module:\", spacy_transformers)\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "print(\"Transformer model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52175b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved as 'intent_with_LogisticRegression.joblib'.\n"
     ]
    }
   ],
   "source": [
    "# Model Training (Intent) Logistic Regression\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# STEP 1: Train from CSV and save model\n",
    "def intent_LogReg(csv_path='intent_dataset_2000.csv'):\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Make sure the expected columns exist\n",
    "    if 'text' not in df.columns or 'intent' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'text' and 'intent' columns\")\n",
    "\n",
    "    texts = df['text'].astype(str).tolist()\n",
    "    labels = df['intent'].astype(str).tolist()\n",
    "\n",
    "    # Pipeline: TF-IDF + Logistic Regression\n",
    "    model = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('clf', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    # Train and save\n",
    "    model.fit(texts, labels)\n",
    "    joblib.dump(model, 'intent_with_LogisticRegression.joblib')\n",
    "    print(\"Model trained and saved as 'intent_with_LogisticRegression.joblib'.\")\n",
    "\n",
    "def extract_intent_LogReg(text, threshold=0.5):\n",
    "    try:\n",
    "        model = joblib.load('intent_with_LogisticRegression.joblib')\n",
    "        probs = model.predict_proba([text])[0]\n",
    "        best_index = probs.argmax()\n",
    "        confidence = probs[best_index]\n",
    "        intent = model.classes_[best_index]\n",
    "\n",
    "        if confidence >= threshold:\n",
    "            return intent, confidence\n",
    "        else:\n",
    "            return \"uncertain\", confidence\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"error: model not found — please run intent_LogReg() first\", 0.0\n",
    "\n",
    "\n",
    "intent_LogReg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a20f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   calculate       1.00      1.00      1.00       400\n",
      "     compare       1.00      1.00      1.00       400\n",
      "     predict       1.00      1.00      1.00       400\n",
      "  shows_info       1.00      1.00      1.00       400\n",
      "\n",
      "    accuracy                           1.00      1600\n",
      "   macro avg       1.00      1.00      1.00      1600\n",
      "weighted avg       1.00      1.00      1.00      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Training (Intent) Random Forest:\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load the dataset (replace path if needed)\n",
    "df = pd.read_csv(\"intent_dataset_2000.csv\")\n",
    "\n",
    "\n",
    "# Split into features and labels\n",
    "X = df[\"text\"]\n",
    "y = df[\"intent\"]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Random Forest classifier\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = rf_model.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(rf_model, \"intent_with_RnFr.joblib\")\n",
    "joblib.dump(vectorizer, \"vectorizer_for_RnFr.joblib\")\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "def extract_intent_RnFr(text, threshold=0.5):\n",
    "    try:\n",
    "        # Load model and vectorizer\n",
    "        model = joblib.load('intent_with_RnFr.joblib')\n",
    "        vectorizer = joblib.load('vectorizer_for_RnFr.joblib')\n",
    "\n",
    "        # Vectorize input\n",
    "        X = vectorizer.transform([text])\n",
    "\n",
    "        # Predict probabilities\n",
    "        probs = model.predict_proba(X)[0]\n",
    "        best_index = np.argmax(probs)\n",
    "        confidence = probs[best_index]\n",
    "        intent = model.classes_[best_index]\n",
    "\n",
    "        if confidence >= threshold:\n",
    "            return intent, confidence\n",
    "        else:\n",
    "            return \"uncertain\", confidence\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"error: model or vectorizer not found — please train and save them first\", 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06ad8b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show_infos\n",
      "3y\n",
      "['AAPL', 'NVDA', 'MSFT']\n"
     ]
    }
   ],
   "source": [
    "# NLP SpaCy \"en_core_web_trf\"\n",
    "import re\n",
    "import spacy\n",
    "import yfinance as yf\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "## == == == -- -- -- Helper Functions -- -- -- == == == ##\n",
    "\n",
    "def preprocess_query(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def run_NER(text):\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "def extract_entities(entities, label):\n",
    "    return [ent_text for ent_text, ent_label in entities if ent_label == label]\n",
    "\n",
    "def to_yf_period(text):\n",
    "    match = re.search(r'(\\d+)\\s*(year|years|month|months|week|weeks|day|days)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        number = match.group(1)\n",
    "        unit = match.group(2).lower()\n",
    "\n",
    "        if 'year' in unit:\n",
    "            return f\"{number}y\"\n",
    "        elif 'month' in unit:\n",
    "            return f\"{number}mo\"\n",
    "        elif 'week' in unit:\n",
    "            days = int(number) * 7\n",
    "            return f\"{days}d\"\n",
    "        elif 'day' in unit:\n",
    "            return f\"{number}d\"\n",
    "    return None\n",
    "\n",
    "def yfinance_search_company(company_names):\n",
    "    results = {}\n",
    "    for name in company_names:\n",
    "        s = yf.Search(name, max_results=1)\n",
    "        if s.quotes:\n",
    "            results[name] = s.quotes[0].get(\"symbol\")\n",
    "        else:\n",
    "            results[name] = None\n",
    "    # Return a list of ticker symbols (filtering out any None values)\n",
    "    return [ticker for ticker in results.values() if ticker]\n",
    "\n",
    "## == == == -- -- -- Main Execute Functions -- -- -- == == == ##\n",
    "def extract_tickers(text):\n",
    "    entities = run_NER(text)\n",
    "    company_names = extract_entities(entities, \"ORG\")\n",
    "    tickers = yfinance_search_company(company_names)\n",
    "    return tickers\n",
    "\n",
    "def extract_intent(text):\n",
    "    result = \"show_infos\"\n",
    "    return result\n",
    "\n",
    "def extract_period(text):\n",
    "    entities = run_NER(text)\n",
    "    date_entities = extract_entities(entities, \"DATE\")\n",
    "\n",
    "    if len(date_entities) >= 2: \n",
    "        print(\"Multiple Date Ranges are not compatible YET. I will add later. Default: max\") \n",
    "        return \"max\"\n",
    "\n",
    "    if len(date_entities) == 1:\n",
    "        period = to_yf_period(text)\n",
    "        if period:\n",
    "            return period\n",
    "        else:\n",
    "            return \"max\"  \n",
    "\n",
    "    return \"max\"\n",
    "\n",
    "\n",
    "raw_query = \"What's the stock of Apple and Nvidia and Microsoft in the past 3 years?\"\n",
    "\n",
    "intent = extract_intent(raw_query)\n",
    "period = extract_period(raw_query)\n",
    "tickers = extract_tickers(raw_query)\n",
    "\n",
    "print(intent) # Not implemented, Default: show_infos\n",
    "print(period)\n",
    "print(tickers)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7172959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lugia\\AppData\\Local\\Temp\\ipykernel_2228\\3518801425.py:33: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  text_input.on_submit(on_submit)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4709c55bb845bfaa984bbfb19b65cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='You:', layout=Layout(width='80%'), placeholder='Type your message here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a885fe3509045a7a3a28af9b1e5de7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import widgets, Layout\n",
    "from IPython.display import display\n",
    "\n",
    "text_input = widgets.Text(\n",
    "    placeholder='Type your message here...',\n",
    "    description='You:',\n",
    "    layout=Layout(width='80%')\n",
    ")\n",
    "\n",
    "output_area = widgets.Output(layout=Layout(border='1px solid black', height='300px', overflow_y='auto'))\n",
    "\n",
    "def on_submit(sender):\n",
    "    user_text = sender.value\n",
    "    if user_text.lower() in ['exit', 'quit']:\n",
    "        with output_area:\n",
    "            print(\"Bot: Goodbye!\")\n",
    "        text_input.value = ''\n",
    "        text_input.disabled = True\n",
    "        return\n",
    "\n",
    "    intent, confidence = extract_intent_RnFr(user_text)\n",
    "    with output_area:\n",
    "        if intent == \"uncertain\":\n",
    "            print(f\"Bot: Sorry, I didn't quite get that. Could you please rephrase or be more specific? (Confidence: {confidence:.2f})\")\n",
    "        elif intent.startswith(\"error:\"):\n",
    "            print(f\"Bot: {intent}\")\n",
    "            text_input.disabled = True\n",
    "        else:\n",
    "            print(f\"Bot: Intent detected -> {intent} (Confidence: {confidence:.2f})\")\n",
    "\n",
    "    text_input.value = ''\n",
    "\n",
    "text_input.on_submit(on_submit)\n",
    "display(text_input, output_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3168025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
