{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec45c29",
   "metadata": {},
   "source": [
    "# This is the simpliest pipeline of Fian.\n",
    "\n",
    "## There are 3 phases\n",
    "\n",
    "- Intent Detection a.k.a NLP layers\n",
    "\n",
    "- Feature Selection\n",
    "\n",
    "- Respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e545ca54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "449f4f18",
   "metadata": {},
   "source": [
    "# Phase 1 - Intent Detection\n",
    "\n",
    "1. Input Preprocessing\n",
    "\n",
    "1. Extract user's intent (using TF-IDF + Logistic Regression)\n",
    "\n",
    "First, for good measure, I will train the model first (train it once and give out a joblib file, but they are here for visualizations)\n",
    "\n",
    "P.S: If you are seeing model and such, means that the part is under developement\n",
    "\n",
    "Second, I will use the model to predict what's the user's intent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63f4bd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma-3-12b-it model loaded\n",
      "en_core_web_trf model loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import spacy\n",
    "import yfinance as yf\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from joblib import load\n",
    "import warnings\n",
    "import google.generativeai as genai\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gemini Gemma-3-12b-it\n",
    "api_key = \"AIzaSyByTfCk2a6m4gkeJAuCpWGmWi8qfyHBQ3w\"\n",
    "generative_model = \"gemma-3-12b-it\"\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(generative_model)\n",
    "print(generative_model + \" model loaded\")\n",
    "# NLP SpaCy \"en_core_web_trf\"\n",
    "spacy_model = \"en_core_web_trf\"\n",
    "\n",
    "nlp = spacy.load(spacy_model)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(spacy_model + \" model loaded\")\n",
    "\n",
    "# models = genai.list_models()\n",
    "# for m in models:\n",
    "#     print(m.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad8b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RSI']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Extractions\n",
    "## == == == -- -- -- Helper Functions -- -- -- == == == ##\n",
    "\n",
    "def preprocess_query(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def run_NER(text):\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "def extract_entities(entities, label):\n",
    "    return [ent_text for ent_text, ent_label in entities if ent_label == label]\n",
    "\n",
    "def to_yf_period(text):\n",
    "    match = re.search(r'(\\d+)\\s*(year|years|month|months|week|weeks|day|days)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        number = match.group(1)\n",
    "        unit = match.group(2).lower()\n",
    "\n",
    "        if 'year' in unit:\n",
    "            return f\"{number}y\"\n",
    "        elif 'month' in unit:\n",
    "            return f\"{number}mo\"\n",
    "        elif 'week' in unit:\n",
    "            days = int(number) * 7\n",
    "            return f\"{days}d\"\n",
    "        elif 'day' in unit:\n",
    "            return f\"{number}d\"\n",
    "    return None\n",
    "\n",
    "def yfinance_search_company(company_names):\n",
    "    results = {}\n",
    "    for name in company_names:\n",
    "        s = yf.Search(name, max_results=1)\n",
    "        if s.quotes:\n",
    "            results[name] = s.quotes[0].get(\"symbol\")\n",
    "        else:\n",
    "            results[name] = None\n",
    "    # Return a list of ticker symbols (filtering out any None values)\n",
    "    return [ticker for ticker in results.values() if ticker]\n",
    "\n",
    "## == == == -- -- -- Main Execute Functions -- -- -- == == == ##\n",
    "\n",
    "def extract_tickers(text):\n",
    "    entities = run_NER(text)\n",
    "    company_names = extract_entities(entities, \"ORG\")\n",
    "    tickers = yfinance_search_company(company_names)\n",
    "    return tickers\n",
    "\n",
    "\n",
    "def extract_intent(text): \n",
    "    # Prompt engineering: add system instruction for better responses\n",
    "    prompt = (\n",
    "        \"You are an intention extraction parser. Given the user's input, return only one of the following intent categories: \"\n",
    "        \"'display_price', 'compare_stocks', 'calculate_indicator', 'predict_indicator', or 'not_stock'.\\n\"\n",
    "        \"Descriptions:\\n\"\n",
    "        \"display_price: The user wants to know the current price or see a visual chart of a specific stock.\\n\"\n",
    "        \"compare_stocks: The user wants to compare two or more stocks.\\n\"\n",
    "        \"calculate_indicator: The user wants to calculate a technical indicator (e.g., RSI, SMA, MACD) for a stock.\\n\"\n",
    "        \"predict_indicator: The user wants a prediction or forecast of a technical indicator for a stock.\\n\"\n",
    "        \"not_stock: The user's input does not relate to stock trading or analysis.\\n\"\n",
    "        \"User: \" + text + \"\\n\"\n",
    "        \"Intent category:\"\n",
    "    )\n",
    "    response = model.generate_content(prompt)\n",
    "    # Extract the intent category from the response (assume it's the first word/line)\n",
    "    intent = response.text.strip().split('\\n')[0].strip().lower()\n",
    "    # Map to expected categories if needed\n",
    "    valid_intents = [\"display_price\", \"compare_stocks\", \"calculate_indicator\", \"predict_indicator\", \"not_stock\"]\n",
    "    if intent in valid_intents:\n",
    "        return intent\n",
    "    # fallback: \n",
    "    return \"ask_again_for_intent\"\n",
    "\n",
    "def extract_period(text):\n",
    "    entities = run_NER(text)\n",
    "    date_entities = extract_entities(entities, \"DATE\")\n",
    "\n",
    "    if len(date_entities) >= 2: \n",
    "        print(\"Multiple Date Ranges are not compatible YET. I will add later. Default: 1y\") \n",
    "        return \"1y\"\n",
    "\n",
    "    if len(date_entities) == 1:\n",
    "        period = to_yf_period(text)\n",
    "        if period:\n",
    "            return period\n",
    "        else:\n",
    "            return \"1y\"  \n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    return \"1y\"\n",
    "def extract_indicator(text):\n",
    "    # Prompt engineering: add system instruction for better responses\n",
    "    indicators = [\n",
    "    \"MACD\", \"MACD_signal\", \"MACD_diff\", \"ADX\", \"CCI\", \"Ichimoku_a\", \"Ichimoku_b\",\n",
    "    \"PSAR\", \"STC\", \"RSI\", \"Stoch\", \"Stoch_signal\", \"AwesomeOsc\", \"KAMA\", \"ROC\", \"TSI\",\n",
    "    \"UO\", \"ATR\", \"Bollinger_hband\", \"Bollinger_lband\", \"Bollinger_mavg\", \"Donchian_hband\",\n",
    "    \"Donchian_lband\", \"Keltner_hband\", \"Keltner_lband\", \"Donchian_width\", \"SMA_5\", \"EMA_5\",\n",
    "    \"WMA_5\", \"DEMA_5\", \"TEMA_5\", \"SMA_10\", \"EMA_10\", \"WMA_10\", \"DEMA_10\", \"TEMA_10\", \n",
    "    \"SMA_20\", \"EMA_20\", \"WMA_20\", \"DEMA_20\", \"TEMA_20\", \"SMA_50\", \"EMA_50\", \"WMA_50\", \n",
    "    \"DEMA_50\", \"TEMA_50\", \"SMA_100\", \"EMA_100\", \"WMA_100\", \"DEMA_100\", \"TEMA_100\", \n",
    "    \"SMA_200\", \"EMA_200\", \"WMA_200\", \"DEMA_200\", \"TEMA_200\"\n",
    "    ]\n",
    "    indicator_comma = ', '.join(indicators)\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an indicator extraction parser. Given the user's input, return a list of technical indicators they want to calculate or predict.\\n\"\n",
    "        \"User: \" + text + \"\\n\"\n",
    "        \"Indicators (comma-separated): \" + indicator_comma + \"\\n\"\n",
    "    )\n",
    "    response = model.generate_content(prompt)\n",
    "    # Extract the indicators from the response (assume they are comma-separated)        \n",
    "    indicators_text = response.text.strip()\n",
    "    if indicators_text:\n",
    "        # Split by commas and strip whitespace\n",
    "        indicators_list = [indicator.strip() for indicator in indicators_text.split(',')]\n",
    "        # Filter out any empty strings\n",
    "        return [indicator for indicator in indicators_list if indicator]\n",
    "    return \"ask_again_for_indicator\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7172959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_price function\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "## == == == -- -- -- Helper Functions -- -- -- == == == ##\n",
    "\n",
    "def extract_data_yf(tickers, Period = \"1y\"): # Note: Remember to make a way to delelte these files after use. Since they are only temporary files.\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        df = yf.download(ticker, period=Period, interval=\"1d\",auto_adjust=True, progress=False)\n",
    "        filename = f\"temp_{ticker}_{Period}.csv\"\n",
    "        df.to_csv(filename)\n",
    "        data[ticker] = df\n",
    "    return data\n",
    "\n",
    "def display_stock(data, n_rows: int = 10):\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        for ticker, df in data.items():\n",
    "            print(f\"\\n=== {ticker}: First {n_rows} rows ===\")\n",
    "            print(df.head(n_rows).to_string())\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        print(f\"=== First {n_rows} rows ===\")\n",
    "        print(data.head(n_rows).to_string())\n",
    "    else:\n",
    "        print(\"Input data must be a dict of DataFrames or a DataFrame.\")\n",
    "\n",
    "def line_graph(df, field: str = \"Close\", title: str = None):\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df.index, df[field])\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(field)\n",
    "    plt.title(title or f\"{field} Price Over Time\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "## == == == -- -- -- Main Execute Function -- -- -- == == == ##\n",
    "def display_stock(tickers, period=\"1y\",visualize=True):\n",
    "    temp_data = extract_data_yf(tickers, Period=period)\n",
    "    for ticker, df in temp_data.items():\n",
    "        print(f\"\\nExtracted data for {ticker}:\")\n",
    "        print(df.head())\n",
    "        if visualize:\n",
    "            line_graph(df, field=\"Close\", title=f\"{ticker} Closing Price Over Time\")\n",
    "\n",
    "\n",
    "\n",
    "# # Test extract_data_yf with FPT Corporation (ticker: FPT) and period 1y\n",
    "# test_tickers = [\"NVDA\"]\n",
    "# test_period = \"1y\"\n",
    "# test_data = extract_data_yf(test_tickers, Period=test_period)\n",
    "# display_stock(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e821084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_stocks function\n",
    "from IPython.display import display\n",
    "\n",
    "## == == == -- -- -- Helper Functions -- -- -- == == == ##\n",
    "\n",
    "\n",
    "def stock_data_side_by_side(multiple_dfs, period=\"1y\"):\n",
    "    if not isinstance(multiple_dfs, dict):\n",
    "        raise ValueError(\"Input must be a dictionary of DataFrames.\")\n",
    "\n",
    "    # Create a new DataFrame to hold the combined data\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for ticker, df in multiple_dfs.items():\n",
    "        # Ensure the index is datetime\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        # Resample to daily frequency if needed\n",
    "        df = df.resample('D').ffill()\n",
    "        # Rename columns to include ticker\n",
    "        df.columns = [f\"{col}_{ticker}\" for col in df.columns]\n",
    "        # Combine with the main DataFrame\n",
    "        combined_df = pd.concat([combined_df, df], axis=1)\n",
    "\n",
    "    # Display as a table (Jupyter will render nicely)\n",
    "    display(combined_df.head())\n",
    "\n",
    "def line_graphs_compare(multiple_dfs, field = \"Close\", title = None):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for ticker, df in multiple_dfs.items():\n",
    "        # Try to find the correct column for the field (e.g., \"Close\", \"Close_AAPL\", (\"Close\", \"AAPL\"))\n",
    "        col = None\n",
    "        # Check for MultiIndex columns\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            for c in df.columns:\n",
    "                if field.lower() in str(c[0]).lower():\n",
    "                    col = c\n",
    "                    break\n",
    "        else:\n",
    "            # Single index columns\n",
    "            for c in df.columns:\n",
    "                if field.lower() in str(c).lower():\n",
    "                    col = c\n",
    "                    break\n",
    "        if col is not None:\n",
    "            plt.plot(df.index, df[col], label=ticker)\n",
    "        else:\n",
    "            print(f\"Field '{field}' not found in {ticker} DataFrame columns: {df.columns}\")\n",
    "\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(field)\n",
    "    plt.title(title or f\"{field} Comparison\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "## == == == -- -- -- Main Execute Functions -- -- -- == == == ##\n",
    "\n",
    "def compare_stocks(tickers, period=\"1y\", visualize=True):\n",
    "    temp_data = extract_data_yf(tickers, Period=period)\n",
    "    stock_data_side_by_side(temp_data, period=period)\n",
    "    if visualize:\n",
    "        line_graphs_compare(temp_data, field=\"Close\", title=f\"Stock Closing Price Comparison for {', '.join(tickers)}\")\n",
    "    return temp_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07d6907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_indicator function\n",
    "\n",
    "from collections import OrderedDict\n",
    "import ta\n",
    "import pandas as pd\n",
    "# Define 30 most used technical indicators using 'ta' library\n",
    "# Use .squeeze() for all df[\"col\"] in indicator lambdas\n",
    "indicator_funcs = OrderedDict({\n",
    "    # Trend indicators\n",
    "    \"MACD\": lambda df: ta.trend.MACD(close=df[\"Close\"].squeeze()).macd(),\n",
    "    \"MACD_signal\": lambda df: ta.trend.MACD(close=df[\"Close\"].squeeze()).macd_signal(),\n",
    "    \"MACD_diff\": lambda df: ta.trend.MACD(close=df[\"Close\"].squeeze()).macd_diff(),\n",
    "    \"ADX\": lambda df: ta.trend.ADXIndicator(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze(), close=df[\"Close\"].squeeze()).adx(),\n",
    "    \"CCI\": lambda df: ta.trend.CCIIndicator(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze(), close=df[\"Close\"].squeeze()).cci(),\n",
    "    \"Ichimoku_a\": lambda df: ta.trend.IchimokuIndicator(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze()).ichimoku_a(),\n",
    "    \"Ichimoku_b\": lambda df: ta.trend.IchimokuIndicator(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze()).ichimoku_b(),\n",
    "    \"PSAR\": lambda df: ta.trend.PSARIndicator(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze(), close=df[\"Close\"].squeeze()).psar(),\n",
    "    \"STC\": lambda df: ta.trend.STCIndicator(close=df[\"Close\"].squeeze()).stc(),\n",
    "\n",
    "    # Momentum indicators\n",
    "    \"RSI\": lambda df: ta.momentum.RSIIndicator(close=df[\"Close\"].squeeze()).rsi(),\n",
    "    \"Stoch\": lambda df: ta.momentum.StochasticOscillator(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze(), close=df[\"Close\"].squeeze()).stoch(),\n",
    "    \"Stoch_signal\": lambda df: ta.momentum.StochasticOscillator(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze(), close=df[\"Close\"].squeeze()).stoch_signal(),\n",
    "    \"AwesomeOsc\": lambda df: ta.momentum.AwesomeOscillatorIndicator(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze()).awesome_oscillator(),\n",
    "    \"KAMA\": lambda df: ta.momentum.KAMAIndicator(close=df[\"Close\"].squeeze()).kama(),\n",
    "    \"ROC\": lambda df: ta.momentum.ROCIndicator(close=df[\"Close\"].squeeze()).roc(),\n",
    "    \"TSI\": lambda df: ta.momentum.TSIIndicator(close=df[\"Close\"].squeeze()).tsi(),\n",
    "    \"UO\": lambda df: ta.momentum.UltimateOscillator(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze(), close=df[\"Close\"].squeeze()).ultimate_oscillator(),\n",
    "\n",
    "    # Volatility indicators\n",
    "    \"ATR\": lambda df: ta.volatility.AverageTrueRange(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze(), close=df[\"Close\"].squeeze()).average_true_range(),\n",
    "    \"Bollinger_hband\": lambda df: ta.volatility.BollingerBands(close=df[\"Close\"].squeeze()).bollinger_hband(),\n",
    "    \"Bollinger_lband\": lambda df: ta.volatility.BollingerBands(close=df[\"Close\"].squeeze()).bollinger_lband(),\n",
    "    \"Bollinger_mavg\": lambda df: ta.volatility.BollingerBands(close=df[\"Close\"].squeeze()).bollinger_mavg(),\n",
    "    \"Donchian_hband\": lambda df: ta.volatility.DonchianChannel(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze()).donchian_channel_hband(),\n",
    "    \"Donchian_lband\": lambda df: ta.volatility.DonchianChannel(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze()).donchian_channel_lband(),\n",
    "    \"Keltner_hband\": lambda df: ta.volatility.KeltnerChannel(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze(), close=df[\"Close\"].squeeze()).keltner_channel_hband(),\n",
    "    \"Keltner_lband\": lambda df: ta.volatility.KeltnerChannel(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze(), close=df[\"Close\"].squeeze()).keltner_channel_lband(),\n",
    "    \"Donchian_width\": lambda df: ta.volatility.DonchianChannel(high=df[\"High\"].squeeze(), low=df[\"Low\"].squeeze()).donchian_channel_width(),\n",
    "})\n",
    "\n",
    "# Add SMA with different window sizes to indicator_funcs\n",
    "for win in [5, 10, 20, 50, 100, 200]:\n",
    "    indicator_funcs[f\"SMA_{win}\"] = lambda df, w=win: ta.trend.SMAIndicator(close=df[\"Close\"].squeeze(), window=w).sma_indicator()\n",
    "    indicator_funcs[f\"EMA_{win}\"] = lambda df, w=win: ta.trend.EMAIndicator(close=df[\"Close\"].squeeze(), window=w).ema_indicator()\n",
    "    indicator_funcs[f\"WMA_{win}\"] = lambda df, w=win: ta.trend.WMAIndicator(close=df[\"Close\"].squeeze(), window=w).wma()\n",
    "    indicator_funcs[f\"DEMA_{win}\"] = lambda df, w=win: ta.trend.DEMAIndicator(close=df[\"Close\"].squeeze(), window=w).dema_indicator()\n",
    "    indicator_funcs[f\"TEMA_{win}\"] = lambda df, w=win: ta.trend.TEMAIndicator(close=df[\"Close\"].squeeze(), window=w).tema_indicator()\n",
    "\n",
    "\n",
    "indicator_plot_config = {\n",
    "    # MACD Family\n",
    "    \"MACD\": {\"type\": \"line\", \"guides\": [0], \"subplot\": True, \"paired\": \"MACD_signal\"},\n",
    "    \"MACD_signal\": {\"type\": \"line\", \"guides\": [0], \"subplot\": True, \"paired\": \"MACD\"},\n",
    "    \"MACD_diff\": {\"type\": \"histogram\", \"guides\": [0], \"subplot\": True},\n",
    "\n",
    "    # Trend Strength\n",
    "    \"ADX\": {\"type\": \"line\", \"guides\": [20, 40], \"subplot\": True},\n",
    "    \"CCI\": {\"type\": \"line\", \"guides\": [-100, 100], \"subplot\": True},\n",
    "\n",
    "    # Ichimoku Cloud\n",
    "    \"Ichimoku_a\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"Ichimoku_b\": {\"type\": \"line\", \"subplot\": False},\n",
    "\n",
    "    # Price Overlay\n",
    "    \"PSAR\": {\"type\": \"scatter\", \"subplot\": False},\n",
    "\n",
    "    # Momentum Oscillators\n",
    "    \"STC\": {\"type\": \"line\", \"guides\": [25, 75], \"subplot\": True},\n",
    "    \"RSI\": {\"type\": \"line\", \"guides\": [30, 70], \"subplot\": True},\n",
    "    \"Stoch\": {\"type\": \"line\", \"guides\": [20, 80], \"subplot\": True, \"paired\": \"Stoch_signal\"},\n",
    "    \"Stoch_signal\": {\"type\": \"line\", \"guides\": [20, 80], \"subplot\": True, \"paired\": \"Stoch\"},\n",
    "    \"AwesomeOsc\": {\"type\": \"histogram\", \"guides\": [0], \"subplot\": True},\n",
    "    \"KAMA\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"ROC\": {\"type\": \"line\", \"guides\": [0], \"subplot\": True},\n",
    "    \"TSI\": {\"type\": \"line\", \"guides\": [0], \"subplot\": True},\n",
    "    \"UO\": {\"type\": \"line\", \"guides\": [30, 70], \"subplot\": True},\n",
    "\n",
    "    # Volatility\n",
    "    \"ATR\": {\"type\": \"line\", \"subplot\": True},\n",
    "    \"Bollinger_hband\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"Bollinger_lband\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"Bollinger_mavg\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"Donchian_hband\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"Donchian_lband\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"Keltner_hband\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"Keltner_lband\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"Donchian_width\": {\"type\": \"line\", \"subplot\": True},\n",
    "\n",
    "    # Moving Averages (Overlays)\n",
    "    \"SMA_5\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"EMA_5\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"WMA_5\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"DEMA_5\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"TEMA_5\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"SMA_10\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"EMA_10\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"WMA_10\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"DEMA_10\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"TEMA_10\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"SMA_20\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"EMA_20\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"WMA_20\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"DEMA_20\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"TEMA_20\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"SMA_50\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"EMA_50\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"WMA_50\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"DEMA_50\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"TEMA_50\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"SMA_100\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"EMA_100\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"WMA_100\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"DEMA_100\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"TEMA_100\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"SMA_200\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"EMA_200\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"WMA_200\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"DEMA_200\": {\"type\": \"line\", \"subplot\": False},\n",
    "    \"TEMA_200\": {\"type\": \"line\", \"subplot\": False},\n",
    "}\n",
    "\n",
    "\n",
    "def visualize_indicator(data, indicator_name, title=None):\n",
    "\n",
    "    config = indicator_plot_config.get(indicator_name, {\"type\": \"line\", \"subplot\": False})\n",
    "    plot_type = config.get(\"type\", \"line\")\n",
    "    guides = config.get(\"guides\", [])\n",
    "    subplot = config.get(\"subplot\", False)\n",
    "    paired = config.get(\"paired\", None)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for ticker, df in data.items():\n",
    "        if indicator_name not in df.columns:\n",
    "            print(f\"{indicator_name} not found in {ticker} data.\")\n",
    "            continue\n",
    "        x = df.index\n",
    "        y = df[indicator_name]\n",
    "        label = f\"{ticker} {indicator_name}\"\n",
    "\n",
    "        if plot_type == \"line\":\n",
    "            plt.plot(x, y, label=label)\n",
    "        elif plot_type == \"histogram\":\n",
    "            plt.bar(x, y, label=label, alpha=0.5)\n",
    "        elif plot_type == \"scatter\":\n",
    "            plt.scatter(x, y, label=label, s=10)\n",
    "        else:\n",
    "            plt.plot(x, y, label=label)\n",
    "\n",
    "        # Plot paired indicator if specified\n",
    "        if paired and paired in df.columns:\n",
    "            plt.plot(x, df[paired], label=f\"{ticker} {paired}\", linestyle=\"--\")\n",
    "\n",
    "    for g in guides:\n",
    "        plt.axhline(g, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    plt.title(title or f\"{indicator_name} Visualization\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(indicator_name)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_ti(df, indicator):\n",
    "    \"\"\"\n",
    "    Calculate one or more technical indicators for a DataFrame using indicator_funcs.\n",
    "    indicator: str or list of str\n",
    "    Returns: DataFrame with new indicator columns added.\n",
    "    \"\"\"\n",
    "    if isinstance(indicator, str):\n",
    "        indicators = [indicator]\n",
    "    else:\n",
    "        indicators = indicator\n",
    "\n",
    "    df = df.copy()\n",
    "    for name in indicators:\n",
    "        func = indicator_funcs.get(name)\n",
    "        if func is not None:\n",
    "            try:\n",
    "                df[name] = func(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating {name}: {e}\")\n",
    "        else:\n",
    "            print(f\"Indicator '{name}' not supported.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_indicator(tickers, period=\"1y\", indicators=None, visualize=True):\n",
    "    temp_data = extract_data_yf(tickers, Period=period)\n",
    "    if indicators is None:\n",
    "        print(\"calculate_indicator: No indicators specified. Returning raw data.\")\n",
    "        return temp_data\n",
    "\n",
    "    for ticker, df in temp_data.items():\n",
    "        print(f\"\\nCalculating indicators for {ticker}...\")\n",
    "        df_with_indicators = calculate_ti(df, indicators)\n",
    "        temp_data[ticker] = df_with_indicators\n",
    "        print(df_with_indicators.tail())\n",
    "\n",
    "    if visualize:\n",
    "        for indicator_name in indicators:\n",
    "            visualize_indicator(temp_data, indicator_name)\n",
    "\n",
    "    return temp_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Calculate and visualize the 50-day SMA for the given tickers and period\n",
    "# Use tickers and period variables already defined in the notebook\n",
    "# calculate_indicator(tickers, period=period, indicators=[\"RSI\"], visualize=True)\n",
    "# print(\"Supported indicators:\")\n",
    "# for name in indicator_funcs.keys():\n",
    "#     print(\"-\", name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Intent Processing and Response Generation\n",
    "def process_intent(intent, raw_query):\n",
    "\n",
    "    if intent == \"not_stock\":\n",
    "        prompt = (\n",
    "            \"This user query does not relate to stock trading or analysis.\\n\"\n",
    "            \"Chat with the user, but do let them know that you are a small stock market assistant and cannot help with this query.\\n\"\n",
    "            \"You can fetch live data, calculate indicators, and predict stock prices.\\n\"\n",
    "            \"User: \" + raw_query + \"\\n\"\n",
    "            \"Response: \"\n",
    "        )\n",
    "        response = model.generate_content(prompt)\n",
    "        print(response.text)\n",
    "\n",
    "    elif intent == \"display_price\":\n",
    "        period = extract_period(raw_query)\n",
    "        tickers = extract_tickers(raw_query)\n",
    "        if tickers:\n",
    "            display_stock(tickers, period=period, visualize=True)\n",
    "        else:\n",
    "            print(\"No valid stock tickers found in the query.\")\n",
    "\n",
    "    elif intent == \"compare_stocks\":\n",
    "        period = extract_period(raw_query)\n",
    "        tickers = extract_tickers(raw_query)\n",
    "        if tickers and len(tickers) > 1:\n",
    "            compare_stocks(tickers, period=period, visualize=True)\n",
    "        else:\n",
    "            print(\"Not enough valid stock tickers found for comparison.\")\n",
    "\n",
    "    elif intent == \"calculate_indicator\":\n",
    "        period = extract_period(raw_query)\n",
    "        tickers = extract_tickers(raw_query)\n",
    "        indicators = extract_indicator(raw_query)\n",
    "        calculate_indicator(tickers, period, indicators, True)\n",
    "\n",
    "    elif intent == \"predict_indicator\": # Going to need to calculate the indicator first, preprocess the data, and then use a model to predict it.\n",
    "        # Having an idea to make a metadata on the best models for each indicator.\n",
    "        # Basically, first time? Run through all models, and then save the best one for each indicator\n",
    "        \n",
    "        if tickers:\n",
    "            indicator = extract_indicator(raw_query)\n",
    "            print(f\"Predicting {indicator} for {', '.join(tickers)} over the period of {period}.\")\n",
    "            # Placeholder for actual prediction logic\n",
    "            # This would typically involve fetching data and applying a prediction model\n",
    "        else:\n",
    "            print(\"No valid stock tickers found for indicator prediction.\")\n",
    "    else: #fallback\n",
    "        print(\"Intent not recognized or not implemented. Please try again with a different query.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9403208a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d50230ba",
   "metadata": {},
   "source": [
    "## Phase 3: NLG using Gemma 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e5864e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! That's a great question! The stock market is essentially a place where shares of publicly-traded companies are bought and sold. Think of it like a giant marketplace for ownership in businesses. People buy and sell these shares, hoping the value will increase over time.\n",
      "\n",
      "However, I'm a small stock market assistant, and my expertise is really focused on helping with things like fetching live stock data, calculating indicators (like moving averages or RSI), and even attempting to predict stock prices. I can't really explain the broader concept of the stock market in detail.\n",
      "\n",
      "If you'd like to explore some stock data or try out a calculation, I'd be happy to help with that! For a more comprehensive understanding of the stock market itself, I'd recommend checking out resources like Investopedia, the SEC website, or a good introductory finance book.\n",
      "\n",
      "\n",
      "\n",
      "What would you like to do related to stocks? Perhaps you're curious about a specific company?\n"
     ]
    }
   ],
   "source": [
    "# Full pipeline: from raw query to intent processing and chat output\n",
    "\n",
    "raw_query = \"What is stock market?\"\n",
    "\n",
    "# Step 1: Preprocess and extract information\n",
    "\n",
    "intent = extract_intent(raw_query)\n",
    "\n",
    "\n",
    "# Step 2: Process intent and output response\n",
    "\n",
    "process_intent(intent, raw_query)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
